{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "urls = [\"https://www.nytimes.com/2024/09/29/us/north-carolina-helene-relief-damage.html\",\"https://www.faz.net/aktuell/wirtschaft/kuenstliche-intelligenz/today-s-ai-can-t-be-trusted-19532136.html\",\"http://www.chinatoday.com.cn/ctenglish/2018/commentaries/202409/t20240925_800378506.html\",\"https://english.elpais.com/economy-and-business/2024-09-28/from-the-hermes-heir-to-nicolas-cage-millionaires-who-went-bankrupt.html\",\"https://insatiable.info/2023/06/30/quels-futur-pour-les-reseaux-sociaux/\",\"https://actu.fr/auvergne-rhone-alpes/lyon_69123/lyon-le-projet-de-reamenagement-des-quais-les-plus-mortels-pour-les-cyclistes-devoile_61667371.html\"]"
      ],
      "metadata": {
        "id": "RfLxuLynRa1_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "msB4ccgtBbrY"
      },
      "outputs": [],
      "source": [
        "import newspaper\n",
        "\n",
        "def download_html(url):\n",
        "    try:\n",
        "        article = newspaper.Article(url)\n",
        "        article.download()\n",
        "        return article.html\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while downloading the article: {e}\")\n",
        "        return None\n",
        "\n",
        "url = \"https://www.nytimes.com/2024/09/29/us/north-carolina-helene-relief-damage.html\"\n",
        "html_content = download_html(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from readabilipy import simple_json_from_html_string\n",
        "\n",
        "article = simple_json_from_html_string(html_content, use_readability=True)"
      ],
      "metadata": {
        "id": "4MndWcSr5gRh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(f\"Title: {article.get('title', 'N/A')}\\n\\n\")\n",
        "    file.write(\"Plain Content:\\n\")\n",
        "    file.write(article.get('plain_content', 'N/A') + \"\\n\\n\")\n",
        "\n",
        "    file.write(\"Plain Text:\\n\")\n",
        "    plain_text = article.get('plain_text', [])\n",
        "    if plain_text:\n",
        "        for paragraph in plain_text:\n",
        "            file.write(paragraph.get('text', '') + \"\\n\")\n",
        "    else:\n",
        "        file.write(\"N/A\\n\")\n",
        "\n",
        "import re\n",
        "\n",
        "with open(\"output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "clean_content = re.sub(r'<.*?>', '', content)\n",
        "\n",
        "with open(\"cleaned_output.txt\", \"w\", encoding=\"utf-8\") as cleaned_file:\n",
        "    cleaned_file.write(clean_content)"
      ],
      "metadata": {
        "id": "cskZGRHXBySP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for url in urls:\n",
        "    i += 1\n",
        "    html_content = download_html(url)\n",
        "    article = simple_json_from_html_string(html_content, use_readability=True)\n",
        "\n",
        "    if article:\n",
        "        cleaned_filename = f\"cleaned_article_{i}.txt\"\n",
        "\n",
        "        with open(cleaned_filename, \"w\", encoding=\"utf-8\") as cleaned_file:\n",
        "            cleaned_file.write(f\"Title: {article.get('title', 'N/A')}\\n\\n\")\n",
        "            cleaned_file.write(\"Plain Text:\\n\")\n",
        "            plain_text = article.get('plain_text', [])\n",
        "            if plain_text:\n",
        "                for paragraph in plain_text:\n",
        "                    cleaned_file.write(paragraph.get('text', '') + \"\\n\")\n",
        "            else:\n",
        "                cleaned_file.write(\"N/A\\n\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to download or process the article from {url}\")"
      ],
      "metadata": {
        "id": "QynDDvc7R6hD"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}